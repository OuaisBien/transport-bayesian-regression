# Bayesian Robust Regression & Optimal Transport for Domain Adaptation
## Overview

This project implements a Probabilistic Domain Adaptation framework to predict Combined Cycle Power Plant (CCPP) energy output under shifting environmental conditions.

By integrating <b>Optimal Transport</b>, specifically the Sinkhorn Algorithm, with <b>Bayesian Robust Regression (HMC)</b>, the model corrects for covariate shifts between "Cold" training days and "Hot" testing days, successfully recovering predictive performance and uncertainty calibration where traditional models fail.

<ul><li>Context: Designed as a proof-of-concept for handling "Curve Deformation" and "Scenario Analysis" in energy grid load forecasting.
</li>
</ul>

## Dataset & Experimental Design

Source: <a href = "https://www.kaggle.com/datasets/rinichristy/combined-cycle-power-plant-data-set-uci-data">UCI Combined Cycle Power Plant Dataset (Kaggle)</a>.

To simulate a realistic future climate scenario (Covariate Shift), the dataset was not split randomly. Instead, it was partitioned based on Ambient Temperature (AT):
<ul><li><b>Source Domain (Training)</b>: The coldest 70% of observations (Winter/Mid-season profile).</li>
<li><b>Target Domain (Testing)</b>: The hottest 30% of observations (Summer/Heatwave profile).</li></ul>
<b>The Challenge</b>: A model trained on "Cold" data typically underestimates uncertainty and fails to generalise to "Hot" regimes due to the shift in feature distribution.

## Methodology: The Hybrid Pipeline

This project moves beyond standard regression by combining Geometric Data Analysis with Probabilistic Inference.
### 1. Geometric Domain Adaptation (Optimal Transport)

We utilise <b>Entropic Optimal Transport (Sinkhorn Algorithm)</b> to bridge the distributional gap between Source and Target features.
<ul>
  <li><b>Algorithm</b>: Unbalanced Sinkhorn-Knopp.</li>
<li><b>Metric</b>: Squared Euclidean distance on standardised features.</li>
<li><b>Output</b>: Importance Weights $\mathbf{w}$ that up-weight "Warm" source samples and down-weight "Cold" samples.</li></li></ul>

### 2. Probabilistic Modeling (Bayesian Inference)

Instead of OLS, we employ a <b>Bayesian Robust Regression</b> using <b>NumPyro (JAX)</b>.
<ul>
  <li><b>Likelihood</b>: Student-T ($\nu$ degrees of freedom) to handle sensor outliers (Robustness).</li>
  <li><b>Inference</b>: NUTS (No-U-Turn Sampler) with Importance Sampling via the OT weights.</li>
  <li><b>Objective</b>: $P(\theta | X_{source}, Y_{source}, \mathbf{w})$</li>
</ul>

## Results & Performance

We compared a <b>Naive Baseline</b> (Standard HMC trained on raw source data) against the <b>OT-Weighted Model</b>.

### Numerical Comparison
		  
| Model	| MAE (MW) | RMSE (MW) | 95% CI Coverage | Interval Width |
|--------|--------|--------|--------|--------|
| Naive Baseline | 4.836 | 6.166 | 0.808 | 16.911 |
| OT-Weighted (Ours) | 4.049 | 5.092 | 0.850 | 15.013 |

### Visualisation

Below is a visualisation of the prediction intervals sorted by power output. Note how the OT-Weighted model (Green) tracks the True Target (Red) better than the Baseline (Blue).

<img src="https://github.com/OuaisBien/transport-bayesian-regression/blob/main/baseline.png" width=500><img src="https://github.com/OuaisBien/transport-bayesian-regression/blob/main/weighted.png" width=500>

## ðŸ’¡ Why Bayesian?
Why not use standard <code>scikit-learn</code> Linear Regression?
<ol>
  <li><b>Risk Management</b>: Standard regression outputs a point estimate. Bayesian regression provides a full posterior distribution, allowing us to calculate tail risks (e.g., "Probability that output drops below 420 MW").</li>
  <li><b>Robustness</b>: The implementation of a Student-T likelihood renders the model resilient to non-Gaussian noise and sensor anomalies common in industrial telemetry.
  <li><b>Regularisation</b>: Priors stabilise the inference against high-variance weights generated by the Optimal Transport algorithm.</li>
</ol>

## Usage
### Requirements
<pre>
<code>
numpyro==0.10.1
jax==0.4.1
pot==0.9.0  # Python Optimal Transport
pandas
matplotlib
</code>
</pre>
